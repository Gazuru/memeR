{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujOfCTplVYi3"
   },
   "source": [
    "# Elméleti háttér, otthoni felkészülési anyag\n",
    "\n",
    "## A labor célja\n",
    "A labor célja, hogy a hallgatókat megismertesse a neurális hálók működésével és használatával, valamint betekintést nyújtson a konvolúciós neurális hálók világába, mely mára már megkerülhetelen az automatikus képfeldolgozás és a gépi látás területén.\n",
    "\n",
    "## Matematikai alapok\n",
    "\n",
    "### Vektorok\n",
    "\n",
    "A koordinátageometriából ismert vektorokat rendszerint $[a, b]$ rendezett számpárokkal jelöljük, melyek első elemét (vagy $x$ koordinátáját) a Descartes féle koordinátarendszer y tengelyétől mért távolságként, második elemét (vagy $y$ koordinátáját) az x tengelytől mért távolságként tudjuk értelmezni. Így a helyvektort ábrázolni tudjuk, az origóból az $x = a$, $y = b$ pontba mutató nyíllal.\n",
    "Ilyen számpárok segítségével a sík minden pontja jellemezhető és a pontokból alkotott halmazokkal a síkbeli alkazatok is előállíthatók. (Pl.: egyenes egyenlete: azon $[a, b]$ koordinátájú pontok halmaza a síkon melyekre valamely $w_0$, $w_1$ súlyok mellett igaz, hogy $b = a * w_1 + w_0$, kör egyenlete, stb.)\n",
    "\n",
    "#### Műveletek vektorokkal\n",
    "\n",
    "Korábbi ismereteinkből tudjuk, hogy \n",
    "- Két vektor összege: $$ [a_1, b_1] + [a_2, b_2]  = [a_1+a_2, b_1+b_2],$$ a koordinátánkénti összegből alkotott számpár.\n",
    "- Egy vektor számszorosa: $$ c \\cdot [a_1, b_1]  = [c \\cdot a_1, c \\cdot b_1],$$ a koordináták adott számszorosából alkotott számpár.\n",
    "- Két vektor skaláris szorzata: $$\\langle [a_1, b_1], [a_2, b_2] \\rangle = a_1  \\cdot a_2 + b_1 \\cdot b_2,$$ az összetartozó koordináták szorzatainak összege. Fontos kiemelni, hogy ennek a műveletnek az eredménye a korábbi kettővel ellentétben nem vektor, hanem egy szám (skalár).\n",
    "\n",
    "#### Távolság\n",
    "\n",
    "Két pont közötti távolság mérésére több lehetséges módszer is adódik. Az első és mindenki által ismert az euklideszi távolság, melynek kiszámolsa $P_1=[a_1, b_1]$ és $P_2=[a_2, b_2]$ pontok esetén $$d_e(P_1, P_2) =  \\sqrt{(a_1-a_2)^2 + (b_1-b_2)^2 }.$$ \n",
    "\n",
    "Ezen túl azonban bizonyos problémák esetén érdemes más fajta távolság mértéket alkalmazni. Egy híres példa a megszokott euklideszi távolságtól különböző távolság mértékre a Manhattan távolság, mely nevét Manhattan híresen szabályos utcáiról kapta. Kiszámítása $P_1=[a_1, b_1]$ és $P_2=[a_2, b_2]$ pontok esetén $$d_e(P_1, P_2) = |a_1-a_2| + |b_1-b_2|,$$ tehát a távolság az x koordináták különbségéhez hozzáadva az y koordináták különbsége. Mintha csak Manhattan két pontja között számolnánk ki, hogy mennyi sétával juthatunk el az egyik pontból a másikba.\n",
    "\n",
    "Szélsőséges példa, de ha meggondoljuk, a háromszög egyenlőtlenség teljesül rá, és bizonyos esetekben hasznos lehet a következő távolságfüggvény:\n",
    "$$d_0(P_1, P_2)=\\begin{cases} 0, & a_1=a_2 \\;\\text{és}\\; b_1=b_2 \\text{ esetén} \\\\  1, & \\text{egyébként}. \\end{cases}$$\n",
    "\n",
    "#### Magasabb dimenziós vektorok\n",
    "A vektorok fogalmát kitejeszthetjük rendezett számhármasokra. Így lehetőségünk van például térbeli pontoknak és alakzatoknak a fentihez hasonló leírására. Számhármasokon a fentiekhez hasonlóan definiálhatjuk a három alapműveletet és a távolság mértékek is kiterjeszthetőek a célnak megfelelően.\n",
    "\n",
    "Így a skaláris szorzat például: \n",
    "$$\\langle [a_1, b_1, c_1], [a_2, b_2, c_2] \\rangle = a_1 \\cdot a_2 + b_1 \\cdot b_2 + c_1 \\cdot c_2,$$ \n",
    "két pont euklideszi távolsága pedig\n",
    " $$d_e(P_1, P_2) =  \\sqrt{(a_1-a_2)^2 + (b_1-b_2)^2 + (c_1-c_2)^2}$$ alakban írható fel.\n",
    "\n",
    "Semmi elméleti akadálya nincsen annak, hogy a vektor fogalmunkat a továbbiakban kiterjesszük szám _n-esekre_, így az n dimenziós tér vektoraira és pontjaira szintén gond nélkül értelmezni tudjuk a korábbi műveleteket és távolságokat. Természetesen ezekhez a pontokhoz és vektorokhoz nem tudunk könnyen értelmezhető ábrákat készíteni vagy a belőlük alkotott alakzatokat elképzelni, de a műveletek alapos ismerete lehetővé teszi, hogy mégis dolgozzunk velük és következtetéseket vonjunk le az általuk leírt világról.\n",
    "\n",
    "Vegyünk egy példát magasabb dimenziós adatra. Ha egy orvos két számmal akarja leírni a betegeit, megteheti, hogy egy $[$_magasság, testsúly_$]$ vektort rendel minden pácienséhez. A pácienseiről a rendelkezésére álló adatok alapján diagramot készíthet, amin a hasonló testfelépítésű emberekhez tartozó adatpontok közel lesznek egymáshoz. Azt mondhatjuk, hogy ha két vektor távolsága kicsi, akkor a két páciens hasonló, ha ez a távolság $0$, akkor a rendelkezésre álló adatok alapján megkülönböztethetetlenek. \n",
    "\n",
    "Ha az orvos könnyebben megkülönböztethetővé akarja tenni pácienseit, megteheti, hogy a $[$_magasság, testsúly, életkor_$]$ vektor alapján ábrázolja őket egy háromdimenziós diagramon. Látható, hogy így korábban megkülönböztethetelen emberek akár \"20 év távolságba\" is kerülhetnek egymástól. További adatok hozzávételével még alaposabb ismereteket szerezhetünk a pácienseinkről. Tegyük fel, hogy rendelkezésünkre áll $[$_magasság, testsúly, életkor, vérnyomás, pulzus szisz, pulszus diasz, test hőmérséklet, szem dioptria, stb..._$]$ vektor. Ekkor már nem egyszerű feladat szemléletes ábrát készíteni a páciensekről, viszont megpróbálkozhatunk például hasonló állapotú páciensek keresésével, hogy azonosítsuk egy betegség potenciális áldozatait. Ehhez megpróbálkozhatunk azzal, hogy adott betegséggel megfertőzött emberekhez tartozó pontokhoz közeli pontokat keresünk a számontartott többi pont között. Ha találunk elég közeli pontokat, akkor az adott pácienseket figyelmeztethetjük, vagy elküldhetjük szűrésre, ezzel megelőzve a nagyobb bajt. \n",
    "\n",
    "Azt is megtehetjük, hogy az egész teret előre felosztjuk zónákra aszerint, hogy az ott lévő pontok (amikhez még nem is feltétlenül tartozik valós páciens) feltételezhetően egészségesek vagy betegek lennének a rendelkezésünkre álló adatok alapján. Így ha egy új páciens érkezik, akkor az előírt általános vizsgálatok elvégzése után könnyen eldönthetjük, hogy el kell-e küldeni további speciális vizsgálatra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TcDbS5ohE2Fv"
   },
   "source": [
    "\n",
    "### Konvolúció\n",
    "A konvolúció a jelfeldolgozásban és azon belül a képfeldolgozásban is gyakran használt művelet. A művelet kimerítő és matematikailag pontos definíciója helyett nézzünk egy példát a képfeldolgozási alkalmazások szempontjából legfontosabb diszkrét 2D konvolúcióra.\n",
    "\n",
    "<center><img width=\"500\" height=\"280\" src=\"https://miro.medium.com/max/669/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif\">\n",
    "<a href=\"https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1\">forrás</a>\n",
    "</center>\n",
    "\n",
    "Legyen adott az 5x5-ös $A$ matrix, azaz a bemeneti kép, továbbá vegyünk egy 3x3-mas $K$ mátrixot (ennek neve kernel mátrix):\n",
    "\n",
    "$$\n",
    "A=\n",
    "\\left(\\begin{array}{cc} \n",
    "3 & 3 & 2 & 1 & 0\\\\\n",
    "0 & 0 & 1 & 3 & 1\\\\\n",
    "3 & 1 & 2 & 2 & 3\\\\\n",
    "2 & 0 & 0 & 2 & 2\\\\\n",
    "2 & 0 & 0 & 0 & 1\n",
    "\\end{array}\\right)\n",
    "K =\n",
    "\\left(\\begin{array}{cc} \n",
    "0 & 1 & 2\\\\\n",
    "2 & 2 & 0\\\\\n",
    "0 & 1 & 2\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "Jelölje $A * K$ a két mátrix konvolúcióját. Ekkor az $A * K = B$ mátrix egyes elemeit a következőképpen számíthatjuk: a $K$ mátrixot az $A$ mátrix fölött az összes lehetséges pozíción \"végigcsúsztatjuk\", és minden pozícióban kiszámoljuk az azonos pozíciójú elemek szorzatát, majd az így kapott értékeket összeadjuk. Az animációban is szemléltetett módon elvégezve a műveletet a következőt kapjuk:\n",
    "$$A * K = B = \n",
    "\\left(\\begin{array}{cc} \n",
    "12 & 12 & 17\\\\\n",
    "10 & 17 & 19\\\\\n",
    "9 & 6 & 14\n",
    "\\end{array}\\right),$$\n",
    "ahol például $14 = 2 \\cdot 0+2 \\cdot 1+3 \\cdot 2+0 \\cdot 2+2 \\cdot 2+2 \\cdot 0+0 \\cdot 0+0 \\cdot 1+1 \\cdot 2$\n",
    "\n",
    "Jól látható, hogy így a kimeneti $B$ mérete kisebb mint az $A$ bemeneté. Ahhoz, hogy ezt elkerüljük, a bemenetet körben ki kell egészíteni plusz pixelekkel. Erre a kitöltésre több mód is van, de a laggyakoribb a nullákkal való kitöltés. Ezt a kiegészítést nevezik _padding_-nek. Példa animáció látható erre is a fenti animáció forrását követve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AO5Aooi6QlA-"
   },
   "source": [
    "## Osztályozás\n",
    "Felügylet tanítás esetén a rendelkezésünkre álló adat mindig bemenet-kimenet párokból áll. (Pl.: $\\{ X=[176, 60, 41, 120, 80, 36.7, -1, stb...]; y=0 \\}$, ahol $X$ a páciens állapotát leíró vektor, $y=0$ jelentése egészséges, $y=1$ pedig beteg.) Osztályozáskor azt a függvényt keressük, ami a bemenethez a kimenetet rendeli. A kimenet ebben az esetben a bemenetek egy csoportosítását adja. A lehetséges osztályok száma bináris osztályozás esetén kettő. Általában lehet akármennyi, de látni fogjuk, hogy elegendő a bináris osztályozás vizsgálata.\n",
    "\n",
    "Legyen adott a 0-ás osztályba tartozó $p_1 = [-1, -2]$ valamint az 1-es osztályba tartozó $p_2 = [1, 2]$ pontok. Ezt az osztályozási problémát könnyen megoldhatjuk, ha $-1$ meredekségű egyenes alatti pontokhoz kéket ($0$), a felette lévő pontokhoz pirosat rendelünk ($1$). Írjuk fel most ennek az egyenesnek az egyenletét a következő módon: $x_1 \\cdot 1+x_2 \\cdot 1+0 = 0$. \n",
    "<center><img src=\"https://i.ibb.co/TcLLLvh/06-pic.png\" width=\"200\"></center>\n",
    "\n",
    "Az ábrán is látható zöld egyenest szeparáló egyenesnek, magasabb dimenziókban egységesen szeparáló síknak nevezzük. A szeparáló egyenes megtalálása két dimenzió és ilyen kevés pont esetén nem volt különösebben nehéz feladat, de sok pont esetén vagy magasabb dimenzióban egyáltalán nem triviális, sőt nem is feltétlenül megoldható feladat.\n",
    "\n",
    "### Neuron\n",
    "A neurális hálókat mesterséges neuronok építik fel. A neuron nevét az emberi agyban található idegsejtről kapta, mely bizonyos mértékű stimuláció hatására (bemeneti jel) aktiválódik és nyúlványán keresztül más idegsejteket stimulál (aktiváció). A hasonlóság - mint látni fogjuk - elsőre kézenfekvő, ám a matematikai modell és a biológiai sejt működése jelentősen eltér. A különbségek taglalása most nem célunk.\n",
    "\n",
    "<center><img src=\"https://i.ibb.co/8g5kd39/09-pic.png\" width=\"350\"></center>\n",
    "\n",
    "A neuron által megvalósított leképezés az n dimenziós $x=[x_1, x_2, ... x_n]$ bemenetre, $\\boldsymbol{w}=[w_1, w_2, ... w_n]$ súlyok és $b$ eltolás mellett:\n",
    "$$sigmoid(\\langle \\boldsymbol{w}, \\boldsymbol{x} \\rangle + b),$$\n",
    "\n",
    "a skáláris szorzat egy súlyozott összegét képzi a bemeneteknek, melyet egy $b$ számmal eltolunk, majd az így kapott értéket képezzük 0 és 1 közé a [sigmoid(.)](https://www.wolframalpha.com/input/?i=1%2F%281%2Be%5E%28-x%29%29+from+-5+to+5) függvénnyel. A sigmoid függvény definíciója:\n",
    "$$sigmoid(x) = \\frac{1}{1+ e^{-x} }$$\n",
    "\n",
    "Az így kapott kimenet felhasználásával rendszerint kerekítéssel hozunk döntést.\n",
    "\n",
    "Két változó esetén a következő alakban írható fel az összefüggés:\n",
    "$$sigmoid(x_1 \\cdot w_1 + x_2 \\cdot w_2+b) = sigmoid(\\langle \\boldsymbol{w} , \\boldsymbol{x} \\rangle +b)$$\n",
    "\n",
    "A korábban felírt szeparáló egyenes egyenlete a következő volt: $x_1 \\cdot 1+x_2 \\cdot 1+0 = 0$. Tehát a fenti osztályozási feladatot megoldhatjuk egy neuronnal melynek súlyvektora $w=[1, 1]$ és az alkalmazott eltolás $b=0$. Ebben az esetben a neuron aktivációjánk számítása részletesen:\n",
    "<center><img src=\"https://i.ibb.co/4KMVjKV/04-pic.png\" width=\"350\"></center>\n",
    "<center><img src=\"https://i.ibb.co/3yrgXXm/05-pic.png\" width=\"350\"></center>\n",
    "\n",
    "A neuron igazi ereje nem az, hogy helyes súlyok megválasztásával meg tudunk oldani osztályozási feladatokat, hanem hogy a modellhez léteznek algoritmusok, melyek elegendő bemenet-kimenet pár megvizsgálásval ki tudnak számítani olyan $w$ súlyokat és $b$ eltolást, melyek használatával a feladat helyes megoldását kapjuk. Az ilyen algoritmusokat nevezzük tanító algoritmusnak. A tanító algoritmusok minden esetben egy hibafüggvény minimalizálására törekednek, mely lehet egyszerűen a rosszul osztályozott minták száma, vagy a szeparáló sík a mintáktól vett távolságának összeg, vagy még sok más.\n",
    "\n",
    "Lineárisan szeparálhatónak nevezzük azokat az osztályozási problémákat, melyek egy neuronal, annak paramétereinek helyes megválasztásával 100%-os pontossággal megoldhatóak. Az első feladatban ilyen probléma megoldása lesz a feladat.\n",
    "<center><img src=\"https://i.ibb.co/xg7zcKj/07-pic.png\" width=\"350\"></center>\n",
    "\n",
    "## Neurális háló\n",
    "Nem minden osztályozási feladat lineárisan szeparálható. Két dimenzióban értelmezve ezt a mondatot ez annyit tesz, hogy nem mindíg elegendő egy egyenes az adataink kettéválasztásához. Ilyen esetekben komplexebb modellekre van szükség, mely megfelelő görbéket tud illeszteni az adatpontjaink köré. A második feladatban olyan problémával fogunk találkozni, melyről ránézésre is látszik, hogy nem megoldható a korábbi modell alkalmazásával.\n",
    "\n",
    "Neurális hálóról akkor beszélünk, ha a problémát több neuron alkalmazásával próbáljuk megoldani úgy, hogy ezeket a neuronokat rétegekbe rendezzük és a rétegek kimenetét a következő réteg bemenetére csatoljuk. Az így kapott rétegek szélességének nevezzük az egy rétegben található neuronok, mélységének az egymás utáni rétegek számát. Sok réteg esetén nagyon mély hálót kapunk. Innen származik a DeepLearning elnevezés.\n",
    "\n",
    "<center><img src=\"https://algorithmia.com/blog/wp-content/uploads/2016/11/neural-network-layers.png\" width=\"350\"></center>\n",
    "\n",
    "A neurális hálók tanítására hasonló algoritmusokat használhatunk, mint egyetlen neuron tanítására. Ezek a modellek már a mélység és a szélesség függvényében bonyolultabb leképezések megtanulására is alkalmasak. A mélységi és szélességi szám növelésének hatását a 2. feladatban lesz lehetőségünk megfigyelni.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lgpUKvZAA8PO"
   },
   "source": [
    "## Konvolúciós Neurális Háló\n",
    "\n",
    "A konvolúció művelete a képfeldolgozásban különösen jelentős. Kereskedelmi forgalomban lévő képszerkesztő alkalmazásokban is találkozhatunk rejtett, vagy direkt alkalmazásával. Használható képek élesítésére,  jellemzők kiemelésére, vagy sok egyéb, bonyolultabb szűrő megvalósítására.\n",
    "\n",
    "Különböző konvolúciós kernelek közvetlen alkalmazásának eredménye:\n",
    "\n",
    "elmosás\n",
    "<center><img src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/06/convolutions_opencv_largeblur-768x286.jpg\" width=\"350\"></center>\n",
    "\n",
    "élesítés\n",
    "<center><img src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/06/convolutions_opencv_sharpen-768x288.jpg\" width=\"350\"></center>\n",
    "\n",
    "élkiemelés\n",
    "<center><img src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/06/convolutions_opencv_sobelx-768x295.jpg\" width=\"350\"></center>\n",
    "\n",
    "[ebben](https://www.pyimagesearch.com/2016/07/25/convolutions-with-opencv-and-python/) a tutorialban.\n",
    "\n",
    "Mint ahogy sima előrecsatolt neurális hálónál is az volt a célunk, hogy bizonyos paramétereit egy modellnek ne előzetes számolással kelljen meghatározni, hanem optimalizáció útján kaphassuk meg, a konvolúciós neurális hálók (CNN - Convolutional Neural Network) esetében is ez a célunk: olyan kernelek tanulása, melyek a kép különböző jellemzőit kiemelve segítik a hálót az automatikus döntéshozásban. \n",
    "\n",
    "Ehhez a korábbi neurális hálóhoz hasonló struktúrát fogunk alkalmazni, de a számokat előállító neuronok helyére ebben az esetben képeket (kép mátrixokat) előállító csatornákat teszünk. Az egymás utáni rétegek közötti súlyokat pedig  konvolúciós kernelekre cseréljük. \n",
    "\n",
    "A jellemző kiemelő konvolúciós rétegek mellett még rengeteg féle rétege lehet egy CNN-nek. Ezek közül most még az átméretező rétegeket emelnénk ki. Ezek szükségességét az indokolja, hogy a bemeneti képek jellemzően nagy felbontásúak, de kevés információt tartalmaznak. (Egy-egy objektum per kép.) Az információk tömörebb ábrázolásának és könnyebb feldolgozásának érdekében a képeket egyre zsugorítjuk. Ehhez _pooling rétegeket_ használunk, melyek közül a MaxPooling a 3. feladatban elő is kerül. Ennek működése egyszerű: beállítható ablakmérettel (a konvolúcióhoz hasonlóan) végigpásztázunk a képen és minden ablakból kiválasztjuk a maximum értéket. Ezt rendszerint nem átlapoló ablakokkal tesszük, hanem a lépésköz mindig megegyezik az ablak méretével.\n",
    "\n",
    "Nézzünk egy példát $2\\times2$-es ablakméretű MaxPoolingra:\n",
    "$$\n",
    "\\left(\\begin{array}{cc} \n",
    "7 & 3 & 5 & 2\\\\\n",
    "8 & 7 & 1 & 6\\\\\n",
    "4 & 9 & 3 & 9\\\\\n",
    "0 & 8 & 4 & 5\n",
    "\\end{array}\\right)\n",
    "\\Rightarrow\n",
    "\\left(\\begin{array}{cc} \n",
    "8 & 6\\\\\n",
    "9 & 9\n",
    "\\end{array}\\right)\n",
    "$$ \n",
    "\n",
    "Szemléletesen mutaja be a konvolúciós és maxpooling réteg egymás után alkalmazását [ez a példaprojekt](http://scs.ryerson.ca/~aharley/vis/conv/flat.html), melyekben kézzel írt számjegyek felismeréséhez használtak CNN-t az alkotók.\n",
    "\n",
    "Jellemző ezekre a modellekre, hogy az egyre mélyebb és mélyebb rétegekben már ember számára nem is értelmezhetőek azok a jellemzők, amik a hálót a döntés meghozatalához segítik.\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iYWZlqScBr6p"
   },
   "source": [
    "# 0. Előkészítés\n",
    "\n",
    "A Runtime menüpont alatt a Change runtime type pontra kattintva állítsa át a \"hardware accelerator type\" beállítást GPU-ra, hogy azt használja a futási környezet hardware-es gyorsítóként!\n",
    "\n",
    "Futtassa az alábbi kódrészletet, hogy az idén nyáron megjelent legújabb stabil Tensorflow verzióval folytathassuk a munkát! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CEkeo2V4oLsQ"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install grpcio==1.24.3\n",
    "!pip install -q tensorflow-gpu==2.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dDcHjuhGCvJs"
   },
   "source": [
    "A Tensorflow frissítése után importáljuk a szükséges csomagokat:\n",
    "- [tensorflow](https://https://www.tensorflow.org/overview): nyílt forráskódú könyvtár gépi tanuláshoz, melyet modellek építéséhez, tanításához és kiértékeléséhez fogunk használni.\n",
    "- [numpy](https://https://numpy.org/): a könyvtár széleskörű támogatást nyújt sokdimenziós tömbök és mátrixok tárolásához, valamint az ezekkel végzett matematikai műveletekhez, függvényekhez. A mai laboron az adathalmazok előállításához és ábrázolásához fogjuk használni.\n",
    "- [matplotlib.pyplot](https://matplotlib.org/api/pyplot_api.html): ábrák készítéséhez és megjelenítéséhez.\n",
    "- os: operációs rendszer műveletekhez, mint fájl olvasás, letöltés, stb.\n",
    " <!-- - datetime: ezt nem fogjuk használni :D (TODO: törölni ezt, ha tényleg nem) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GUQrtr1cfJ-g",
    "outputId": "2dd67945-1e78-4f4b-be65-224ada136c77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "#TF verzió ellenőrzése\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pkXbDofXiwJx"
   },
   "source": [
    "# 1. Lineáris osztályozás egyszerű neuronnal\n",
    "\n",
    "Az első feladatban egy, a bevezetőben bemutatotthoz hasonló lineárisan szeparálható bináris osztályozási feladattal találkozunk.\n",
    "Az adathalmaz előállítása és ábrázolása után egy neuron betanításával fogjuk megoldani a problémát. \n",
    "A feladat során figyelje meg a tanító algoritmus viselkedését a konvergencia sebessége és a pontosság szempontjából!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "64d0QzguK3c4"
   },
   "source": [
    "Futtassa az alábbi kódrészletet, hogy a későbbiekben lehetőség legyen egyszerűen ábrázolni a 2D adatokon a modellek predikcióit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "udeUcwSvSEsp"
   },
   "outputs": [],
   "source": [
    "def plot_grid_of_model(model, inputs, labels):\n",
    "  # Dontesi felulet abrazolasahoz grid letrehozasa\n",
    "  # Tengelyek menti kiterjedés\n",
    "  x_min = inputs[:, 0].min() - 0.2;\n",
    "  x_max = inputs[:, 0].max() + 0.2;\n",
    "  y_min = inputs[:, 1].min() - 0.2;\n",
    "  y_max = inputs[:, 1].max() + 0.2;\n",
    "\n",
    "  h = (x_max - x_min)/50.0 # grid pontjainak tavolsaga\n",
    "  xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "  grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
    "\n",
    "  # Grid celláinak osztalyozasa a paraméterben átadott modell segítségével\n",
    "  grid_predictions = model.predict(grid_points)\n",
    "  grid_predictions_drawing = grid_predictions.reshape(xx.shape)\n",
    "\n",
    "  # Ábra inicializálása\n",
    "  # fig1, ax2 = plt.subplots(constrained_layout=True)\n",
    "  fig1, ax2 = plt.subplots()\n",
    "\n",
    "  # Tanítóminták kirajzolása\n",
    "  for i in range(len(labels)):\n",
    "      if(labels[i] == 1.0):\n",
    "          ax2.plot(inputs[i,0], inputs[i,1], 'ro')\n",
    "      else:\n",
    "          ax2.plot(inputs[i,0], inputs[i,1], 'bo')\n",
    "\n",
    "  # A grid celláinak kirajzolása a fenti korábbi oszályozás alapján \n",
    "  CS = ax2.contourf(xx, yy, grid_predictions_drawing, \n",
    "                11,  cmap='jet', \n",
    "              #  [0, 0.5, 1], colors=['b', 'r'],\n",
    "                alpha=0.5, vmin=0, vmax=1)\n",
    "\n",
    "  # A szeparáló görbe berajzolása\n",
    "  CS2 = ax2.contour(CS, levels=[0.5], colors='g')\n",
    "  cbar = fig1.colorbar(CS)\n",
    "  cbar.add_lines(CS2)\n",
    "\n",
    "  ax2.set_title('Osztályozás 1 neuronnal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q9REdV8ei2bN"
   },
   "source": [
    "## Tanítóhalmaz létrehozása\n",
    "\n",
    "Kezdjük a feladatot az adathalmaz létrehozásával!\n",
    "Először lineárisan szeparálható, bináris osztályozási feladatot fogunk előkészíteni. \n",
    "\n",
    "A címkék legyenek a 0 és az 1. \n",
    "\n",
    "A 0 címkéjű osztály:\n",
    "- pontjai helyezkedjenek az $x_2 = 2 \\cdot x_1+7$ egyenletű egyenes mentén, ahol $0 < x_1 <  5$,\n",
    "- legyen 300 elemű,\n",
    "- a mintákhoz keverjünk $0$ várhatóértékű, $0.5$ szórású, normális eloszlású zajt!\n",
    "\n",
    "A 1 cimkéjű osztály:\n",
    "- pontjai helyezkedjenek az $x_2 = 2 \\cdot x_1-1$ egyenletű egyenes mentén, ahol $0 < x_1 <  5$,\n",
    "- legyen 300 elemű,\n",
    "- a mintákhoz keverjünk $0$ várhatóértékű, $0.5$ szórású, normális eloszlású zajt!\n",
    "\n",
    "A feladat helyes megoldásával a következőhöz hasonló ábrát kell kapnia:\n",
    "\n",
    "<center><img src=\"https://i.ibb.co/N7Q3M67/10-pic.png\" width=\"350\"></center>\n",
    "\n",
    "Ehhez az alábbi kódrészletben már elő van készíte az 1-es címkéjű osztály pontjainak generálása, címkézése és kirajzolása. \n",
    "\n",
    "**Feladat:**\n",
    "- Egészítse ki a kódrészletet a másik osztály előkészítéséhez szükséges kóddal!\n",
    "- Adjon $0$ várhatóértékű, $0.5$ szórású, normális eloszlású zajt az adatokhoz! ([segítség](https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html))\n",
    "- Adja meg az új pontok címkéit!\n",
    "- Végül egészítse ki az ábrát az új pontokkal! A 0-s osztály pontjai kékek legyenek! ([segítség](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ckPYNfBToRec"
   },
   "outputs": [],
   "source": [
    "#********************************\n",
    "#            Mintak\n",
    "#********************************\n",
    "# Első osztály mintái\n",
    "class_1_x1 = np.linspace(0.0, 5.0, 300)  #shape: (300,)\n",
    "class_1_x2 = 2*class_1_x1-1 #shape: (300,)\n",
    "class_1 = np.column_stack((class_1_x1, class_1_x2))  #shape: (300, 2)\n",
    "\n",
    "# Masodik osztaly mintai\n",
    "class_0_x1 = ...\n",
    "class_0_x2 = ...\n",
    "class_0 = ...\n",
    "\n",
    "inputs = np.row_stack((class_1, class_0))          #shape: (600, 2)\n",
    "\n",
    "# Normalis i.i.d. zajjal pertubalas\n",
    "# https://docs.scipy.org/doc/numpy-1.15.0/reference/generated/numpy.random.normal.html\n",
    "\n",
    "noise = ...\n",
    "inputs = inputs + noise\n",
    "\n",
    "\n",
    "#********************************\n",
    "#            Cimkék\n",
    "#********************************\n",
    "\n",
    "label_1 = np.repeat(1.0, 300)           #shape: (300,)\n",
    "label_0 = ...\n",
    "labels = np.concatenate((label_1, label_0))      #shape: (600,)\n",
    "labels = np.expand_dims(labels, 1)                #shape: (600, 1)\n",
    "\n",
    "print(inputs.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# Kirajzolása\n",
    "for i in range(600):\n",
    "    if(labels[i] == 1.0):\n",
    "        plt.plot(inputs[i,0], inputs[i,1], 'ro')\n",
    "    else: ...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EVzelHH7jHsg"
   },
   "source": [
    "## Neuron létrehozása\n",
    "\n",
    "Most, hogy az adathalmaz készen áll, folytassuk a neuron létrehozásával. Ezt ebben a feladatban egy egy rétegű neurális hálóval fogjuk megvalósítani, melynek egyetlen rétege egyetlen neuront tartalmaz.\n",
    "\n",
    "**Feladat:**\n",
    "- A [Sequential](https://www.tensorflow.org/api_docs/python/tf/keras/Sequential) osztály segítségével hozzon létre egy neurális hálót!\n",
    "- A hálónak egy [Dense](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) rétege legyen, mely pontosan 1 neuront tartalmaz!\n",
    "- Alkalmazzon [Sigmoid](https://www.tensorflow.org/api_docs/python/tf/keras/activations/sigmoid) aktivációs függvényt!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kqX3E11-oUst"
   },
   "outputs": [],
   "source": [
    "model = ...\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.005),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FmBh0F7XS8TT"
   },
   "source": [
    "Ha minden igaz, a modell összefogalásának kiíratása után látjuk, hogy három tanítható paramétere lett a hálónak. Ezek a korábban használt jelölés szerint a w_1, w_2 és b paraméterek.\n",
    "\n",
    "<center><img src=\"https://i.ibb.co/8g5kd39/09-pic.png\" width=\"350\"></center>\n",
    "\n",
    "Mint azt már korábban láttuk, ezek a paraméterek szoros összefüggésben állnak a szeparáló egyenessel. Mi ez az összefüggés?\n",
    "\n",
    "**Feladat:**\n",
    "- Próbáljon meg (iteratív próbálgatással, vagy számolással) olyan $w_1$, $w_2$, $b$ paramétereket találni, amelyek mellett a háló (maximum 1-2 pontot leszámítva) helyesen osztályozza az adathalmaz pontjait! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgqHFi2yoXU6"
   },
   "outputs": [],
   "source": [
    "w_1=0.0\n",
    "w_2=-0.5\n",
    "b=0.5\n",
    "\n",
    "model.layers[0].set_weights((np.array([[w_1], [w_2]]), np.array([b])))\n",
    "\n",
    "plot_grid_of_model(model, inputs, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MhKBVAsZW0jh"
   },
   "source": [
    "Ha sikerült megfelelő paramétereket találni, nézzük meg, hogyan lehet ezt hasonló kezdeti konfigurációból ($w_1=0.0, w_2=-0.5, b=0.5$) iteratív tanító algoritmussal elérni!\n",
    "\n",
    "**Feladat:**\n",
    "- Nézzen utána a [Model](https://www.tensorflow.org/api_docs/python/tf/keras/Model) osztály [fit](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) metódusának!\n",
    "- Egészítse ki az alábbi kódrészletet a tanító lépéssel és figyelje meg az ábrák segítségével a tanítás folyamatát!\n",
    "- Ha szükségesnek érzi, vegye nagyobbra (vagy kisebbre) a _num_epochs_ váltózó értékét!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QY3MIMarobBI"
   },
   "outputs": [],
   "source": [
    "model.layers[0].set_weights((np.array([[0.0], [-0.5]]), np.array([0.5])))\n",
    "\n",
    "plot_grid_of_model(model, inputs, labels)\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "num_epochs: Az a szám, hogy hányszor engedjük a tanítás során végig nézni az algoritmusnak a teljes adathalmazt. \n",
    "Ebben a feladatban egyelőre ne használjuk fit() hasonló nevű paraméterét!\n",
    "\"\"\"\n",
    "num_epochs = 5\n",
    "for i in range(num_epochs):\n",
    "  ... fit ...\n",
    "  plot_grid_of_model(model, inputs, labels)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ukV8PoNqZ1rh"
   },
   "source": [
    "Ha elégedettek vagyunk az eredménnyel, nézzük meg az optimalizáció után kapott paramétereket. Van összefüggés ezek és az általunk kézzel beállított paraméterek között?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8fqATB5UofbJ"
   },
   "outputs": [],
   "source": [
    "(w_1, w_2), b = model.layers[0].get_weights()\n",
    "print('w_1=', w_1)\n",
    "print('w_2=', w_2)\n",
    "print('b=', b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4mNsOcc7YxgY"
   },
   "source": [
    " # 2. Osztályozás Neurális Hálóval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d8Eo6yL3-bPv"
   },
   "source": [
    "## Tanítóhalmaz létrehozása\n",
    "\n",
    "Kezdjük a feladatot ismét az adathalmaz létrehozásával!\n",
    "\n",
    "Adathalmazunk most a következő ábrához hasonlóan fog kinézni:\n",
    "\n",
    "<center><img src=\"https://i.ibb.co/jwBPwKp/11-pic.png\" width=\"350\"></center>\n",
    "\n",
    "**Feladat:**\n",
    "- Adja meg az új pontok címkéit!\n",
    "- Egészítse ki az ábrát az új pontokkal! A 0-s osztály pontjai kékek legyenek!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "beQHVsKNojR9"
   },
   "outputs": [],
   "source": [
    "#********************************\n",
    "#           PARAMETEREK\n",
    "#********************************\n",
    "num_samples = 5*50\n",
    "variance = 0.22\n",
    "\n",
    "#********************************\n",
    "#            MINTAK\n",
    "#********************************\n",
    "class_1 = np.repeat([0.0, 0.0], 3*num_samples//5).reshape(-1, 2)\n",
    "\n",
    "x = np.linspace(0, 6.26, 2*num_samples//5)\n",
    "class_0_x1 = np.cos(x)\n",
    "class_0_x2 = np.sin(x)\n",
    "class_0 = np.column_stack((class_0_x1, class_0_x2))\n",
    "\n",
    "inputs = np.row_stack((class_1, class_0))\n",
    "\n",
    "# Mintak pertubacioja normal i.i.d zajjal\n",
    "noise = np.random.normal([0.0, 0.0], variance, [num_samples, 2])\n",
    "inputs = inputs + noise\n",
    "\n",
    "#********************************\n",
    "#            CIMKEK\n",
    "#********************************\n",
    "# Osztaloyk cimkei\n",
    "label_1 = np.repeat(1.0, 3*num_samples//5)\n",
    "label_0 = ...\n",
    "\n",
    "labels = np.concatenate((label_1, label_0))\n",
    "labels = np.expand_dims(labels, 1)\n",
    "print(labels.shape)\n",
    "\n",
    "# Tanitomintak megjelenitese\n",
    "for i in range(num_samples):\n",
    "    if(labels[i] == 1.0):\n",
    "        plt.plot(inputs[i,0], inputs[i,1], 'ro')\n",
    "    else: ...\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjmalQh1dLj6"
   },
   "source": [
    "Először próbáljuk meg megoldani a feladatot az előző feladatban látott hálóval!\n",
    "\n",
    "**Feladat:**\n",
    "- Hozzon létre egy az előzőhöz hasonló modellt (1 réteg, 1 neuron, sigmoid aktiváció)\n",
    "- A korábbihoz hasonlóan egészítse ki a tanító ciklust a tanító lépéssel, majd futtassa a cellát!\n",
    "- Most már nem vagyunk kíváncsiak a ábrára az összes lépés után. Vegye magasabbra a _fit()_ függvény _epochs_ paraméterét!\n",
    "- Mit tapasztal? Mit gondol, miért történik ez?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EPxGG3zFom5c"
   },
   "outputs": [],
   "source": [
    "model_2 = ...\n",
    "\n",
    "model_2.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_2.summary()\n",
    "\n",
    "\n",
    "plot_grid_of_model(model_2, inputs, labels)\n",
    "plt.show()\n",
    "for i in range(10):\n",
    "  ... fit(... epochs=10)  ...\n",
    "  plot_grid_of_model(model_2, inputs, labels)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZBDB-ZqgzWO"
   },
   "source": [
    "Ezután próbáljuk meg megoldani a feladatot egyetlen neuron helyett egy összetettebb hálóval!\n",
    "\n",
    "**Feladat:**\n",
    "- a) Hozzon létre két Dense rétegből álló neurális hálót! \n",
    " - Az új réteg legyen az 1 neuronból álló `sigmoid` aktivációt alkalmazó réteg előtt,\n",
    " - tartalmazzon 2 neuront, és alkalmazzon `relu` aktivációt!\n",
    " - dokumentálja a következő cellában, hogy mit tapasztal!\n",
    "- b) \n",
    " - cserélje az első Dense rétegben a neuronok számát 3-ra!\n",
    " - dokumentálja a következő cellában, hogy mit tapasztal!\n",
    "- c) \n",
    " - cserélje az első Dense rétegben a neuronok számát 10-re!\n",
    " - dokumentálja a következő cellában, hogy mit tapasztal!\n",
    "\n",
    "- d) Hozzon létre három Dense rétegből álló nerális hálót! \n",
    " - Az új réteg legyen az 1 neuronból álló `sigmoid` aktivációt alkalmazó réteg előtt,\n",
    " - a két rejtett réteg tartalmazzon 2-2 neuront, és alkalmazzon `relu` aktivációt!\n",
    " - dokumentálja a következő cellában, hogy mit tapasztal!\n",
    "- e) \n",
    " - cserélje a két rejtett rétegben a neuronok számát 5-re!\n",
    " - dokumentálja a következő cellában, hogy mit tapasztal!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WTr5gHyMopsb"
   },
   "outputs": [],
   "source": [
    "model_3 = ...\n",
    "\n",
    "model_3.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.05),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_3.summary()\n",
    "\n",
    "\n",
    "plot_grid_of_model(model_3, inputs, labels)\n",
    "plt.show()\n",
    "for i in range(20):\n",
    "  ... fit(... epochs=10)  ...\n",
    "  plot_grid_of_model(model_3, inputs, labels)\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hhyIGcvml83q"
   },
   "source": [
    "Mit lát 1 rejtett réteg esetén, 2 neuront alkalmazva? Mit gondol miért?\n",
    "\n",
    "...\n",
    "\n",
    "Mit lát 1 rejtett réteg esetén, 3 neuront alkalmazva?\n",
    "\n",
    "...\n",
    "\n",
    "Mit lát 1 rejtett réteg esetén, 10 neuront alkalmazva?\n",
    "\n",
    "...\n",
    "\n",
    "Mit lát 2 rejtett réteg esetén, 2-2 neuront alkalmazva?\n",
    "\n",
    "...\n",
    "\n",
    "Mit lát 2 rejtett réteg esetén, 5-5 neuront alkalmazva?\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-xdepjplbAUq"
   },
   "source": [
    " # 3. Képek osztályozása Neurális Hálóval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNEPZmuypt3U"
   },
   "source": [
    "A továbbiakban képek osztályozásával fogunk foglalkozni.\n",
    "\n",
    "Módszerekkel való ismerkedéshez és modellek teszteléséhez gyakran használunk mesteréges adathalmazt, mert azok könnyebben kezelehőek. Például az 1. feladat esetén direkt úgy hoztuk létre az adatokat, hogy linearisan szeparálható problémát kapjunk. A való életben laggyakrabban nem ismerjük előre az adathalmazunk tulajdonságait, csak a rendelkezésünkre álló minták alapján próbálhatunk következtetni ezekre.\n",
    "\n",
    "A továbbiakban egy valós képekből álló adatbázissal fogunk dolgozni. Az adatbázisban fényképek vannak, melyek a kutya és macska osztályba vannak sorolva. A fényképek tekinthetőek sokdimenziós vektoroknak, ahol *magasság* *x* *szélesség* darab számmal, avagy pixszelekkel írjuk le a tárolni kívánt adatot. Ezek az adat pontok aztán a korában látottakhoz hasonlóan használhatóak egy neurális háló tanítására. A Dense rétegeket tartalmazó hálók helyett most konvolóciós hálókkal fogunk foglalkozni, melyek a képfeldolgozás területén sokkal megbízhatóbb eredményeket adnak. \n",
    "\n",
    "Futtassa az alábbi kódrészletet az adatbázis letöltéséhez!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UHupSyHPa9zL"
   },
   "outputs": [],
   "source": [
    "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
    "\n",
    "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
    "\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qlmJCMDMiUYS"
   },
   "source": [
    "Az képek a számítógépen most a következő fájlstuktúrában vannak:\n",
    "```\n",
    "[cats_and_dogs_filtered]\n",
    "┣━[train]\n",
    "┃  ┣━[cats]\n",
    "┃  ┃  ┣━cat.0.jpg\n",
    "┃  ┃  ┣━cat.1.jpg\n",
    "┃  ┃  ┗━...\n",
    "┃  ┗━[dogs]\n",
    "┃     ┣━dog.0.jpg\n",
    "┃     ┣━dog.1.jpg\n",
    "┃     ┗━...\n",
    "┣━[validation]\n",
    "┃  ┣━[cats]\n",
    "┃  ┃  ┣━cat.2000.jpg\n",
    "┃  ┃  ┣━cat.2001.jpg\n",
    "┃  ┃  ┗━...\n",
    "┃  ┗━[dogs]\n",
    "┃     ┣━dog.2000.jpg\n",
    "┃     ┣━dog.2001.jpg\n",
    "┃     ┗━...\n",
    "┗━vectorize.py\n",
    "```\n",
    "Ha a későbbiekben macska-kutya detektortól különböző feladatot szeretnénk megoldani a minta képeinket hasonló fájlstruktúrában tárolhatjuk.\n",
    "\n",
    "A train mappában a tanításhoz használt képek a validation mappában a kiértékaléshez használt képek találhatóak meg. Ennek a szétválasztásank azért van fontos szerepe, hogy a modelljeink általánosító képességét is tesztelni tudjuk. Az alábbi kódrészletben a validation mappa elemeit szintén két részre szedjük. Így az első részt fogjuk `validation split`-nek nevezni a másodikat `test split`-nek. \n",
    "\n",
    "Így árom adathalmazt kapunk melek sorra:\n",
    "- train: ezeket az adatkoat használjuk a tényleges tanításra\n",
    "- validation: ezeket az adatokat hasznájuk a tanítás közbeni kiértékelére. Ennek haszna, hogy például le tudjuk állítani a tanulást, ha a validation spliten csökkenni kezd a pontosság.\n",
    "- test: a harmadik részét a képeknek a teljes tanítás utáni kiértékelésre használhatjuk. \n",
    "\n",
    "A túltanulás témaköréről többet az érdeklődők [itt](https://towardsdatascience.com/overfitting-vs-underfitting-a-complete-example-d05dd7e19765) olvashatnak.\n",
    "\n",
    "Az alábbi kódrészlet nem tölti be a képeket, hanem azt definiálja, hogy a különböző elérési utakkal adott képeket hogyan kell betölteni. Ez fontos különbség a gépi tanulásban, ugyanis gyakran megesik, hogy a feldolgozni kívánt adat nem fér bele a memóriába. Mivel nekünk a tanítás során soha nem lesz szükségünk egyszerre az összes képre (mindíg csak éppen 128-ra) így nem is érdemes telerakni a memóriát ezekkel a képekkel. Az adatbázis tehát továbbra is csak linkeket tartalmez, a képek csak  `on demand` módon töltődnek ba a háttértárról. \n",
    "\n",
    "Futtassa az alábbi kódrészletet a három elkülönített adathalmaz elkészítéséhez!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "IgDljwbxbpfz",
    "outputId": "ae644407-4da7-4b0b-a0d2-3e6141e2b63f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(PATH, 'train')\n",
    "validation_dir = os.path.join(PATH, 'validation')\n",
    "\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
    "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
    "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
    "\n",
    "num_cats_tr = len(os.listdir(train_cats_dir))\n",
    "num_dogs_tr = len(os.listdir(train_dogs_dir))\n",
    "\n",
    "num_cats_val = len(os.listdir(validation_cats_dir))\n",
    "num_dogs_val = len(os.listdir(validation_dogs_dir))\n",
    "\n",
    "total_train = num_cats_tr + num_dogs_tr\n",
    "total_val = num_cats_val + num_dogs_val\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 15\n",
    "IMG_HEIGHT = 64\n",
    "IMG_WIDTH = 64\n",
    "\n",
    "train_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255) # Generator for our training data\n",
    "validation_image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255, validation_split=0.5) # Generator for our validation data\n",
    "\n",
    "train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                           directory=train_dir,\n",
    "                                                           shuffle=True,\n",
    "                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                           class_mode='binary')\n",
    "\n",
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary',\n",
    "                                                              subset='training')\n",
    "\n",
    "test_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='binary',\n",
    "                                                              subset='validation')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2XWFScNwR-pf"
   },
   "source": [
    "Az alábbi kódrészlettel ábrázolhatjuk a test adatbázis random 25 képét. Eből jól látszik, hogy a cimkézés a fentiekhez hasonlóan nullával és eggyel történik, ahol a 0 a macskát az 1 a kutyát jelenti. A neurális háló feladata pedig jelen esetben is a bemenethez (kép egy állatról) a kimenet rendelésének megtanulása lesz (0-hoz közelebbi számok: macska,  1-hez közelebbi számok: kutya)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AAIq_8kxoulX"
   },
   "outputs": [],
   "source": [
    "sample = next(test_data_gen)\n",
    "\n",
    "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
    "def plotImages(images, labels):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i, (image, label) in enumerate(zip(images[:25], labels[:25])):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image)\n",
    "        # The CIFAR labels happen to be arrays, \n",
    "        # which is why you need the extra index\n",
    "        plt.xlabel(str('cat' if label < 0.5 else 'dog') + ': ' + str(label))\n",
    "    plt.show()\n",
    "    \n",
    "plotImages(sample[0], sample[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2N6ZtReSuOK"
   },
   "source": [
    "Az alábbi kódrészletben egy konvolúciós rétegeket és MaxPooling rétegből álló neurális háót definiálunk. Futtassa az alábbi kódrészletet és magyarázza meg, hogy mit jelent a kimeneten a `max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0` sor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFvtNtfJoxKu"
   },
   "outputs": [],
   "source": [
    "model_4 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(IMG_HEIGHT, IMG_WIDTH ,3)),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_4.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XW2x8SXrTEvB"
   },
   "source": [
    "A `MaxPooling2 (None, 8, 8, 64)          0` sor jelentése:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oMhbY04PTRht"
   },
   "source": [
    "Az alábbi kódrészlet a korábban használt fit() metódusokhoz hasonló. A fit_generátor a fit-től anyiban különbözik, hogy ennek a most használt generátorokat, míg az előzőnek a korábban hasznlát előre előkészített adatbázist kell átadni.\n",
    "\n",
    "Futtassa az alábbi kódrészlete a CNN tanításához!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qydvzkIio0E9"
   },
   "outputs": [],
   "source": [
    "epochs = 15\n",
    "\n",
    "history = model_4.fit_generator(\n",
    "    epochs=epochs,\n",
    "    generator=train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rpEkab8Io3AU"
   },
   "outputs": [],
   "source": [
    "test_loss, test_acc = model_4.evaluate(test_data_gen)\n",
    "\n",
    "print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XzhvHosFo5ZE"
   },
   "outputs": [],
   "source": [
    "preds = model_4.predict(sample)\n",
    "\n",
    "plotImages(sample[0], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3eRdsI4SXF5B"
   },
   "source": [
    "Az így tanított modell láthatóan nem tökéletes. Ha minden igaz 60% körüli pontosságra képes. Ez a véletlenszerű döntésnél kicsit jobb, de természetesen a céltől még nagyon messze van. Nézzen utána következő rétegekenk és/vagy módszereknek és próáljon javítni a háló teljestíményén!\n",
    "\n",
    "Tippek:\n",
    "- Több epoch (ha van rá idő)\n",
    "- Több konvolóciós-MaxPooling réteg pár\n",
    "- Több csatorna rétegenként\n",
    "- Learning_rate megválasztása\n",
    "- [Drop out](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout)\n",
    "- [Batch normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization)\n",
    "- [Augmentáció](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)\n",
    "- [Regularization](http://neuralnetworksanddeeplearning.com/chap3.html#regularization)([TF](https://www.tensorflow.org/api_docs/python/tf/keras/regularizers/l2))\n",
    "\n",
    "\n",
    "Dokumentélja, hogy milyen változtatásokat végzett és hogy sikerült-e javítani a háló pontosságán!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wSc472EXcgH"
   },
   "source": [
    "Változtatások:\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BProf MI labor 5 - Neuralis Halok.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
